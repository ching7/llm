# 模型评估脚本说明

## 概述

`evaluate.py` 是用于评估微调后模型性能的脚本，与训练脚本 `sft_train.py` 完全兼容。

## 主要功能

### 1. **自动设备检测**
- 自动检测芯片类型（Intel/Apple Silicon）
- Intel Mac 自动使用 CPU
- Apple Silicon 自动使用 MPS（如果可用）
- 与训练脚本的设备选择逻辑一致

### 2. **数据格式兼容**
- 支持与训练脚本相同的数据格式：`query`, `response`, `tag`
- 支持 JSON 和 JSONL 格式
- Prompt 格式与训练脚本完全一致

### 3. **评估功能**
- 逐个样本评估模型输出
- 自动提取模型生成的响应
- 与期望输出进行匹配度检查
- 计算整体匹配率

### 4. **结果保存**
- 保存详细的评估结果到 JSON 文件
- 包含每个样本的输入、期望输出、模型输出和匹配状态

## 使用方法

### 基本用法

```bash
# 使用默认参数评估
python evaluate.py

# 默认参数：
# --model_path: ../outputs/sft_results/final_model
# --data_path: ../data/self_cognition.jsonl
# --output_path: ../outputs/evaluation_results.json
# --device: 自动检测
# --max_new_tokens: 200
```

### 自定义参数

```bash
# 指定模型路径和数据路径
python evaluate.py \
    --model_path ../outputs/sft_results/final_model \
    --data_path ../data/self_cognition.jsonl \
    --output_path ../outputs/my_evaluation_results.json

# 指定设备
python evaluate.py --device cpu

# 调整生成长度
python evaluate.py --max_new_tokens 300
```

### 参数说明

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| `--model_path` | str | `../outputs/sft_results/final_model` | 微调后的模型路径 |
| `--data_path` | str | `../data/self_cognition.jsonl` | 评估数据集路径（支持 json/jsonl） |
| `--output_path` | str | `../outputs/evaluation_results.json` | 评估结果保存路径 |
| `--device` | str | `None` (自动检测) | 使用的设备（cpu/mps/cuda） |
| `--max_new_tokens` | int | `200` | 生成的最大 token 数 |

## 数据格式

评估脚本支持与训练脚本相同的数据格式：

### JSONL 格式示例

```jsonl
{"query": "你是？", "response": "我是{{CHENYANAN DE MODEL }}，由{{CHENYANAN}}训练的人工智能助手。", "tag": "zh"}
{"query": "你是谁", "response": "我是一个由{{CHENYANAN}}开发的人工智能助手。", "tag": "zh"}
```

### JSON 格式示例

```json
[
  {
    "query": "你是？",
    "response": "我是{{CHENYANAN DE MODEL }}，由{{CHENYANAN}}训练的人工智能助手。",
    "tag": "zh"
  },
  {
    "query": "你是谁",
    "response": "我是一个由{{CHENYANAN}}开发的人工智能助手。",
    "tag": "zh"
  }
]
```

## Prompt 格式

评估脚本使用的 prompt 格式与训练脚本完全一致：

```
### 输入:
{query}

### language:
{tag}

### 输出:
```

## 输出结果

### 控制台输出

评估过程中会显示：
- 设备信息
- 每个样本的输入、模型输出、期望输出
- 匹配度（✓/✗）
- 最终统计信息（总样本数、匹配数、匹配率）

### JSON 结果文件

保存的 JSON 文件包含：

```json
[
  {
    "query": "你是？",
    "tag": "zh",
    "expected_response": "我是{{CHENYANAN DE MODEL }}，由{{CHENYANAN}}训练的人工智能助手。",
    "model_response": "我是{{CHENYANAN DE MODEL }}，由{{CHENYANAN}}训练的人工智能助手。",
    "match": true
  },
  ...
]
```

## 评估指标

脚本会计算以下指标：
- **总样本数**：评估数据集中的样本总数
- **匹配样本数**：模型输出与期望输出匹配的样本数
- **匹配率**：匹配样本数 / 总样本数 × 100%

## 示例输出

```
💻 检测到 Intel 芯片，使用 CPU 设备进行评估
📦 加载模型: ../outputs/sft_results/final_model

正在加载分词器...
正在加载模型...
正在加载评估数据集...

开始评估，共 10 个样本...

============================================================
📝 评估样本 1/10
============================================================

📥 输入:
  Query: 你是？
  Language: zh

🤖 模型输出:
  我是{{CHENYANAN DE MODEL }}，由{{CHENYANAN}}训练的人工智能助手。

✅ 期望输出:
  我是{{CHENYANAN DE MODEL }}，由{{CHENYANAN}}训练的人工智能助手。

📊 匹配度: ✓

...

============================================================
📊 评估总结
============================================================
总样本数: 10
匹配样本数: 8
匹配率: 80.00%
============================================================

🎉 评估完成！
📁 详细结果已保存到: ../outputs/evaluation_results.json
```

## 注意事项

1. **设备选择**：脚本会自动检测设备，Intel Mac 会使用 CPU，Apple Silicon 会使用 MPS
2. **内存管理**：MPS 设备会自动使用 float16 以节省内存
3. **数据格式**：确保评估数据格式与训练数据格式一致
4. **模型路径**：确保模型路径正确，包含 `config.json` 和模型权重文件

## 与训练脚本的兼容性

- ✅ 使用相同的数据格式（`query`, `response`, `tag`）
- ✅ 使用相同的 prompt 格式
- ✅ 使用相同的设备检测逻辑
- ✅ 支持相同的模型类型

## 故障排除

### 问题：找不到模型文件
**解决**：检查 `--model_path` 参数，确保路径正确

### 问题：数据格式不匹配
**解决**：确保数据文件包含 `query`, `response`, `tag` 字段

### 问题：MPS 内存不足
**解决**：脚本会自动使用 CPU，或手动指定 `--device cpu`

### 问题：生成结果不完整
**解决**：增加 `--max_new_tokens` 参数值

